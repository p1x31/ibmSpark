{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we already provide an RDD object, so please have a look at the RDD API in order to find out what function to use: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD\n",
    "\n",
    "The following link contains additional documentation: https://spark.apache.org/docs/latest/rdd-programming-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
    "\n",
    "\n",
    "if ('sc' in locals() or 'sc' in globals()):\n",
    "    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n",
    "#sudo add-apt-repository ppa:linuxuprising/java\n",
    "#sudo apt install oracle-java14-installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4950"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please use the following two links for your reference: https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD https://spark.apache.org/docs/latest/rdd-programming-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt50(i):\n",
    "    if i > 50:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(gt50(4))\n",
    "print(gt50(51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt50(i):\n",
    "    return i > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(gt50(4))\n",
    "print(gt50(51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt50 = lambda i: i > 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's shuffle our list to make it a bit more interesting\n",
    "from random import shuffle\n",
    "l = list(range(100))\n",
    "shuffle(l)\n",
    "rdd = sc.parallelize(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87,\n",
       " 53,\n",
       " 66,\n",
       " 96,\n",
       " 74,\n",
       " 70,\n",
       " 90,\n",
       " 55,\n",
       " 83,\n",
       " 58,\n",
       " 56,\n",
       " 92,\n",
       " 64,\n",
       " 93,\n",
       " 77,\n",
       " 82,\n",
       " 80,\n",
       " 59,\n",
       " 75,\n",
       " 85,\n",
       " 79,\n",
       " 91,\n",
       " 63,\n",
       " 94,\n",
       " 86,\n",
       " 98,\n",
       " 68,\n",
       " 78,\n",
       " 76,\n",
       " 65,\n",
       " 89,\n",
       " 54,\n",
       " 60,\n",
       " 81,\n",
       " 73,\n",
       " 72,\n",
       " 62,\n",
       " 51,\n",
       " 71,\n",
       " 99,\n",
       " 67,\n",
       " 97,\n",
       " 95,\n",
       " 61,\n",
       " 69,\n",
       " 57,\n",
       " 84,\n",
       " 88,\n",
       " 52]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(gt50).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87,\n",
       " 53,\n",
       " 66,\n",
       " 96,\n",
       " 74,\n",
       " 70,\n",
       " 90,\n",
       " 55,\n",
       " 83,\n",
       " 58,\n",
       " 56,\n",
       " 92,\n",
       " 64,\n",
       " 93,\n",
       " 77,\n",
       " 82,\n",
       " 80,\n",
       " 59,\n",
       " 75,\n",
       " 85,\n",
       " 79,\n",
       " 91,\n",
       " 63,\n",
       " 94,\n",
       " 86,\n",
       " 98,\n",
       " 68,\n",
       " 78,\n",
       " 76,\n",
       " 65,\n",
       " 89,\n",
       " 54,\n",
       " 60,\n",
       " 81,\n",
       " 73,\n",
       " 72,\n",
       " 62,\n",
       " 51,\n",
       " 71,\n",
       " 99,\n",
       " 67,\n",
       " 97,\n",
       " 95,\n",
       " 61,\n",
       " 69,\n",
       " 57,\n",
       " 84,\n",
       " 88,\n",
       " 52]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda i: i > 50).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s consider the same list of integers. Now we want to compute the sum for elements in that list which are greater than 50 but less than 75. Please implement the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53,\n",
       " 66,\n",
       " 74,\n",
       " 70,\n",
       " 55,\n",
       " 58,\n",
       " 56,\n",
       " 64,\n",
       " 59,\n",
       " 63,\n",
       " 68,\n",
       " 65,\n",
       " 54,\n",
       " 60,\n",
       " 73,\n",
       " 72,\n",
       " 62,\n",
       " 51,\n",
       " 71,\n",
       " 67,\n",
       " 61,\n",
       " 69,\n",
       " 57,\n",
       " 52]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x: x > 50).filter(lambda x: x < 75).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.filter(lambda x: x > 50).filter(lambda x: x < 75).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
